{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install bs4 selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from webdriver_manager.utils import ChromeType\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "# from lxml import etree\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome('chromedriver',options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.99.co/singapore/sale/hdb\")\n",
    "links=[]\n",
    "count = 0\n",
    "webcount = 0\n",
    "first = True\n",
    "while True:\n",
    "  try:\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    #time.sleep(5)\n",
    "    linkclass = soup.find_all('a', class_='_3Ajbv _30I97 _1vzK2')\n",
    "    for l in linkclass:\n",
    "      links.append(l['href'])\n",
    "    nextbutton = \"https://www.99.co\" + soup.find('li', class_='next').find('a')['href']\n",
    "  except:\n",
    "    driver.refresh()\n",
    "  else:\n",
    "    while True:\n",
    "      try:\n",
    "        if count == 20:\n",
    "            driver = webdriver.Chrome('chromedriver',options=chrome_options)\n",
    "            count = 0\n",
    "        driver.get(nextbutton)\n",
    "        time.sleep(5)\n",
    "      except:\n",
    "         driver = webdriver.Chrome('chromedriver',options=chrome_options)\n",
    "      else:\n",
    "        count+=1\n",
    "        webcount+=1\n",
    "        break\n",
    "\n",
    "  if webcount==228:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver',options=chrome_options)\n",
    "t_page_source=[]\n",
    "for link in links:\n",
    "  if(count == 20):\n",
    "    driver = webdriver.Chrome('chromedriver',options=chrome_options)\n",
    "    count = 0\n",
    "  else:\n",
    "    pass\n",
    "  driver.get(\"https://www.99.co\" + link)\n",
    "  while True:\n",
    "  # time.sleep(5)\n",
    "    soup = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "    trans = soup.find(id=\"transactions\")\n",
    "    t_page_source.append(trans) \n",
    "    try:\n",
    "      # nextbutton = soup.find('li', class_='RIVsn')\n",
    "      t_nextbutton = driver.find_element(By.CLASS_NAME,\"RIVsn\")\n",
    "      t_nextbutton.click()\n",
    "      time.sleep(5)\n",
    "      count+=1\n",
    "    except:\n",
    "      break\n",
    "  time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in t_page_source:\n",
    "  if t!= None:\n",
    "    row1 = t.find_all('tr',class_=\"_3zkEn _1kKgW\")\n",
    "    row2 = t.find_all('tr',class_=\"_1kKgW\")\n",
    "    t_data = []\n",
    "    for r in row1:\n",
    "      t_data.append( r.find_all('td',class_=\"gcin4 _2kf8F\"))\n",
    "    for r in row2:\n",
    "      t_data.append( r.find_all('td',class_=\"gcin4 _2kf8F\"))\n",
    "    for a in t_data:\n",
    "      for r in range(len(a)):\n",
    "        if(r==0):\n",
    "          d = int(a[r].get_text()[3:])\n",
    "        elif(r==1):\n",
    "          b = a[r].get_text()\n",
    "        elif(r==3):\n",
    "          x = a[r].get_text().split(\" \")\n",
    "          af = int(x[0].replace(',', ''))\n",
    "          am = float(x[2].replace(',', ''))\n",
    "        elif(r==4):\n",
    "          x = a[r].get_text().split(\" \")\n",
    "          if \"M\" in x[0][2:]:\n",
    "            p = float(x[0][2:-1].replace(',', '')) * 10**6\n",
    "          else:\n",
    "            p = int(x[0][2:].replace(',', ''))\n",
    "          pf = float(x[1][3:].replace(',', ''))\n",
    "      df2=df2.concat({'Date' : d,'Block' : b,'Areasqft' : af, 'Areasqm' : am, 'Price' : p, 'Pricesf' : pf}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "encoder = OrdinalEncoder()\n",
    "df2['Block'] = encoder.fit_transform(df2[['Block']])\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('residential.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
